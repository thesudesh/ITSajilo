<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../../CSS/header_footer.css">
    <link rel="stylesheet" href="../../CSS/syllabus_subjects.css">
    <title>  Neural Networks Syllabus</title>
</head>
<body>
    <!-- THis part contains the FOOTER of the page -->
    <!-- COPY AND PASE THE PROVIDED CODE OF THE HEADER HEERE -->
    
    <!-- The header of the page -->
    <script
    src="https://code.jquery.com/jquery-3.3.1.js"
    integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60="
    crossorigin="anonymous">
    </script>
    <div id="header"></div>

  <!-- tHE MAIN BODY -->
  <!--Remaining section-->


    <!-- Main Syllabus part of the page -->
    <!-- EDIT THE CONTENTS OF THE PAGE HERE -->
    <main>
        <!-- The topbar of the page -->
        <!-- Shows the image and the semester selected. -->
        <section class="topfirst">
            <!-- The leftside -->
            <!-- CHANGE THE ANCHOR TAG BELOW ON EACH SEMESTER -->
            <a href="../../SUBJECT_SELECTIONS/FIrst-sem.html"><h1><span class="textColor1">Sixth </span><span class="textColor2">Semester</span></h1></a>

            <!-- the right image -->
            <img src="../../Resources/svg/online_articles.svg" alt="Selction Image">

        </section>

         <!-- Main Subject's Name -->
         <h1 class="s_name"> Neural Networks</h1>
        <!-- THe main syllabus -->
        <section class="mainSyllabus">
           

            <!-- DIsplays the subjects credit, full marks, pass marks -->
            <section class="topbar_syllabus">
                <section class="syllabus_top_left">
                    <p><b> Course Title:</b>  Neural Networks</p>  
                    <p><b> Course No.:</b> CSC372</p>  
                    <p><b> Course Nature:</b> Theory + Lab</p>
                    <p><b> Semester:</b> Sixth </p>
                    <p><b> Year:</b> Third</p>
    
                </section>
                <selection class="syllabus_top_right">
                    <p><b> Full Marks: </b> 60 + 20 + 20</p>
                    <p><b> Pass Marks: </b> 24 + 8 + 8 </p>
                    <p><b> Credit Hours:</b> 3</p>
                </selection>
            </section>


            <section>
                <p><b> 
                    Course Description:
                </b> 
                The  course  introduces  the  underlying  principles  and  design  of Neural  Network.  The  course covers the basics concepts of Neural Network including: its architecture, learning processes, single layer and multilayer perceptron followed by Recurrent Neural Network                </p>

                <p><b> 
                    Course Objectives:    
                </b> 
                The  course  objective  is  to  demonstrate  the  concept  of  supervised  learning,  unsupervised learning in conjunction with different architectures of Neural Network.                </p>
            </section>

            <!-- Display the syllabus with the chapter's name and everything. -->
            <section class="syllabus_table">
                <table>
                    <!-- The main heading for the table -->
                    <tr>
                        <th><h4>Contents of Chapter</h4></th>
                    </tr>
                    <!-- Add the row below in table as needed for chapters -->
                    <!-- Unit-1 -->
                    <tr>
                        <td>
                            <h4>Unit 1: Introduction to Neural Network (4 Hrs.)</h4>


                            <p>
                                Basics of neural networks and human brain, Models of a neuron, Neural Network viewed as Directed  Graphs,  Feedback,  Network  Architectures,  Knowledge  Representation,  Learning Processes, Learning Tasks                            </p>
                        </td>
                    </tr>

                    <!-- Unit-2-->
                    <tr>
                        <td>
                            <h4>Unit 2: Rosenblatt’s Perceptron (3 Hrs.)</h4>


                            <p>
                                Introduction,  Perceptron,  The  Perceptron  Convergence  Theorem,  Relation  between  the Perceptron   and   Bayes   Classifier   for   a   Gaussian   Environment,   The   Batch   Perceptron Algorithm                            </p>
                        </td>
                    </tr>

                     <!-- Unit-3-->
                     <tr>
                        <td>
                            <h4>Unit 3: Model Building through Regression(5 Hrs.)</h4>


                            <p>
                                Introduction,  Linear  Regression  Model:  Preliminary  Considerations,  Maximum a  Posteriori Estimation   of   the   Parameter   Vector,   Relationship   Between   Regularized   Least-Squares Estimation   and   Map   Estimation,   Computer   Experiment:   Pattern   Classification,   The Minimum-Description-Length Principle, Finite Sample-Size Considerations, The instrumental-Variables Method                            </p>
                        </td>
                    </tr>

                     <!-- Unit-4-->
                    <tr>
                        <td>
                            <h4>Unit 4: The Least-Mean-Square Algorithm(5 Hrs.)</h4>


                            <p>
                                Introduction,  Filtering  Structure  of  the  LMS  Algorithm,  Unconstrained  Optimization:  A Review,  The  Wiener  Filter,  The  Least-Mean-Square  Algorithm,  Markov  Model  Portraying the Deviation  of  the  LMS  Algorithm  from  the  Wiener  Filter,  The  Langevin  Equation: Characterization of Brownian Motion, Kushner‟s Direct-Averaging Method, Statistical LMS Learning  Theory  for  Small  Learning-Rate  Parameter,  Virtues  and  Limitations  of  the  LMS Algorithm, Learning-Rate Annealing Schedules                            </p>
                        </td>
                    </tr>

                    <!-- Unit-5-->
                    <tr>
                        <td>
                            <h4>Unit 5: Multilayer Perceptron(8 Hrs.)</h4>


                            <p>
                                Introduction, Batch Learning and On-Line Learning, The Back-Propagation Algorithm, XOR problem,  Heuristics  for  Making  the  back-propagation  Algorithm  Perform  Better,  Back Propagation  and  Differentiation,  The  Hessian  and  Its  Role  in  On-Line  Learning,  Optimal Annealing  and  Adaptive  Control  of  the  Learning  Rate,  Generalization,  Approximations  of Functions,  Cross  Validation,  Complexity  Regularization  and  Network  Pruning,  Virtues  andLimitations  of  Back-Propagation  Learning,  Supervised  Learning  Viewed  as  Optimization Problem,  Convolutional  Networks,  Nonlinear  Filtering,  Small-Scale  Versus  Large-Scale Learning Problems                            </p>
                        </td>
                    </tr>

                    <!-- Unit-6-->
                    <tr>
                        <td>
                            <h4>Unit 6: Kernel Methods and Radial-Basis Function Networks (7 Hrs.)</h4>


                            <p>
                                Introduction, Cover‟s Theorem on the separability of Patterns, The Interpolation problem, Radial-Basis-Function  Networks,  K-Means  Clustering,  Recursive  Least-Squares  Estimation of the Weight Vector, Hybrid Learning Procedure for RBF Networks, Kernel Regression and Its Relation to RBF Networks                            </p>
                        </td>
                    </tr>

                    <!-- Unit-7-->
                    <tr>
                        <td>
                            <h4>Unit 7: Self-Organizing Maps(6 Hrs.)</h4>


                            <p>
                                Introduction,  Two  Basic  Feature-Mapping  Models,  Self-Organizing  Map,  Properties  of  the Feature  Map,  Contextual  Maps,  Hierarchical  Vector  Quantization,  Kernel  Self-Organizing Map, Relationship between Kernel SOM and Kullback-Leibler Divergence                            </p>
                        </td>
                    </tr>

                    <!-- Unit-8-->
                    <tr>
                        <td>
                            <h4>Unit 8: Dynamic Driven Recurrent Networks (7 Hrs.)</h4>


                            <p>
                                Introduction,    Recurrent    Network    Architectures,    Universal    Approximation    Theorem, Controllability  and  Observability,  Computational  Power  of Recurrent  Networks,  Learning Algorithms,  Back  Propagation  through  Time,  Real-Time  Recurrent  Learning,  Vanishing Gradients  in  Recurrent  Networks,  Supervised  Training  Framework  for  Recurrent  Networks Using  Non  Sate  Estimators,  Adaptivity  Considerations,  CaseStudy:  Model  Reference Applied to Neurocontrol                            </p>
                        </td>
                    </tr>

                    

                    
                </table>

            </section>

            
            <!-- LAB WORKS, BOOKS, REFERENCE BOOKS -->
            <section class="bottom_bar">
                <!-- LAB WORKS SECTION -->
                <section>
                    <h3><b>
                        Laboratory Works: 
                    </b></h3>

                    <p>
                        Practical  should  be  focused  on  Single  Layer  Perceptron,  Multilayer  Perceptron,  Supervised Learning,  Unsupervised  Learning,  Recurrent  Neural  Network,  Linear  Prediction  and  Pattern Classification                    </p>

                     
                </section>

                <!-- TEXT BOOKS SECTION -->
                <section class="text_book">
                    <h3><b>
                        Text Books:
                    </b></h3>
                    <ol>
                        <li>Simon Haykin, Neural Networks and Learning Machines, 3rdEdition, Pearson</li>
                    </ol>
                </section>
                
                <!-- REFERENCE BOOKS -->
                <section class="ref_book">
                    <h3><b>
                        Reference Books:
                    </b></h3>
                    <ol>
                        <li>Christopher M. Bishop, Neural Networks for Pattern Recognition, Oxford University Press,2003</li>
<li>Martin T. Hagan, Neural Network Design, 2ndEdition PWS pub co.</li>
                        
                    </ol>
                </section>
            </section>
        
    </main>

    <!-- THis part contains the FOOTER of the page -->
    <!-- COPY AND PASE THE PROVIDED CODE OF THE FOOTER HEERE -->
    <!-- fOOTER SECTION -->
    
    <div id="footer"></div>
    <script> 
    $(function(){
    
        $("#header").load("../../HTML/hf/header_sem_select.html"); 
        $("#footer").load("../../HTML/hf/footer_sem_select.html"); 
    });
    </script> 
</body>
</html>